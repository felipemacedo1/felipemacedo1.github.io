name: Daily Activity Aggregation

on:
  schedule:
    - cron: '0 6 * * *'  # Daily at 06:00 UTC for current year
  workflow_dispatch:
    inputs:
      year:
        description: 'Target year (e.g., 2024). If empty, uses current UTC year.'
        required: false
        type: string
      username:
        description: 'GitHub username'
        required: true
        type: string
        default: 'felipemacedo1'

permissions:
  contents: write

jobs:
  aggregate-data:
    concurrency:
      group: data-aggregation-${{ github.event.inputs.username || 'default' }}-${{ github.event.inputs.year || 'current' }}
      cancel-in-progress: false
    runs-on: ubuntu-latest

    env:
      ITEMS_PER_PAGE: 100
      BASE_DELAY: 1
      MAX_RETRIES: 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        run: |
          # Ensure jq is available
          if ! command -v jq >/dev/null 2>&1; then
            echo "Installing jq..."
            sudo apt-get update -qq
            sudo apt-get install -y jq
          fi
          
          # Verify token availability
          if [[ -z "${{ secrets.GH_PAT }}" ]]; then
            echo "::error::GH_PAT secret is required but not set"
            exit 1
          fi

      - name: Configure workflow parameters
        id: config
        run: |
          # Set target year (default to current UTC year)
          if [[ -n "${{ github.event.inputs.year }}" ]]; then
            TARGET_YEAR="${{ github.event.inputs.year }}"
          else
            TARGET_YEAR=$(date -u +%Y)
          fi

          # Validate year format and range
          if ! [[ "$TARGET_YEAR" =~ ^[0-9]{4}$ ]] || (( TARGET_YEAR < 2008 || TARGET_YEAR > $(date -u +%Y) )); then
            echo "::error::Invalid year: $TARGET_YEAR (must be 2008-$(date -u +%Y))"
            exit 1
          fi

          # Set target user
          if [[ -n "${{ github.event.inputs.username }}" ]]; then
            TARGET_USER="${{ github.event.inputs.username }}"
          else
            TARGET_USER="felipemacedo1"
          fi

          # Validate username format
          if ! [[ "$TARGET_USER" =~ ^[a-zA-Z0-9]([a-zA-Z0-9-]*[a-zA-Z0-9])?$ ]]; then
            echo "::error::Invalid username format: $TARGET_USER"
            exit 1
          fi

          DATA_DIR="analytics"
          OUTPUT_FILE="${DATA_DIR}/activity-${TARGET_YEAR}-${TARGET_USER}.json"
          
          # Calculate 365-day range (from 365 days ago to today)
          DAYS_365_START=$(date -u -d "365 days ago" +%F)
          TODAY=$(date -u +%F)
          ROLLING_OUTPUT_FILE="${DATA_DIR}/activity-rolling-365d-${TARGET_USER}.json"

          # Export variables
          {
            echo "target_year=$TARGET_YEAR"
            echo "target_user=$TARGET_USER"
            echo "output_file=$OUTPUT_FILE"
            echo "rolling_output_file=$ROLLING_OUTPUT_FILE"
            echo "twelve_months_start=$DAYS_365_START"
            echo "today=$TODAY"
            echo "data_dir=$DATA_DIR"
          } >> "$GITHUB_OUTPUT"
          
          echo "✓ Configuration: year=$TARGET_YEAR, user=$TARGET_USER"
          echo "✓ Rolling 365-day range: $DAYS_365_START to $TODAY"

      - name: Aggregate repository activity data
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          set -euo pipefail

          YEAR=${{ steps.config.outputs.target_year }}
          USER=${{ steps.config.outputs.target_user }}
          OUT_FILE=${{ steps.config.outputs.output_file }}
          ROLLING_OUT_FILE=${{ steps.config.outputs.rolling_output_file }}
          TWELVE_MONTHS_START=${{ steps.config.outputs.twelve_months_start }}
          TODAY=${{ steps.config.outputs.today }}
          DATA_DIR=${{ steps.config.outputs.data_dir }}

          mkdir -p "$DATA_DIR"

          # API configuration - CRITICAL: Use cloak-preview header for Search Commits API
          ACCEPT_HEADER="Accept: application/vnd.github.cloak-preview+json"
          AUTH_HEADER="Authorization: Bearer $GH_PAT"

          # Enhanced API request function with exponential backoff
          api_request() {
            local url=$1
            local attempt=1
            
            while (( attempt <= MAX_RETRIES )); do
              local response
              response=$(curl -sSL \
                -H "$ACCEPT_HEADER" \
                -H "$AUTH_HEADER" \
                "$url" 2>/dev/null) || {
                echo "::warning::Network error on attempt $attempt"
                if (( attempt >= MAX_RETRIES )); then
                  echo "::error::Max retries exceeded for: $url"
                  return 1
                fi
                local delay=$((BASE_DELAY * (2 ** (attempt - 1))))
                echo "Retrying in ${delay}s..."
                sleep "$delay"
                attempt=$((attempt + 1))
                continue
              }

              # Check for API errors
              local error_msg
              error_msg=$(echo "$response" | jq -r '.message? // empty' 2>/dev/null || echo "")
              
              if [[ -n "$error_msg" ]]; then
                if [[ "$error_msg" == *"rate limit"* ]] || [[ "$error_msg" == *"API rate limit exceeded"* ]]; then
                  echo "::warning::Rate limit hit on attempt $attempt: $error_msg"
                  if (( attempt >= MAX_RETRIES )); then
                    echo "::error::Rate limit persists after $MAX_RETRIES attempts"
                    return 1
                  fi
                  local delay=$((BASE_DELAY * (2 ** attempt)))
                  echo "Backing off for ${delay}s..."
                  sleep "$delay"
                  attempt=$((attempt + 1))
                  continue
                else
                  echo "::error::API error: $error_msg"
                  echo "::debug::Full response: $response"
                  return 1
                fi
              fi

              # Success
              printf "%s" "$response"
              return 0
            done
          }

          # Process API response pages for a date range
          process_range_pages() {
            local start_date=$1
            local end_date=$2
            local activity_array_ref=$3
            local query="author:${USER} committer-date:${start_date}..${end_date}"
            local page=1

            while true; do
              echo "Processing page $page for range $start_date..$end_date"
              local encoded_query
              encoded_query=$(printf '%s' "$query" | jq -sRr @uri)
              local api_url="https://api.github.com/search/commits?q=${encoded_query}&per_page=${ITEMS_PER_PAGE}&page=${page}"
              
              local response
              response=$(api_request "$api_url") || return 1

              # Extract items
              local items
              items=$(echo "$response" | jq -c '.items[]?' 2>/dev/null || echo "")
              if [[ -z "$items" ]]; then
                break
              fi

              # Process each item
              while IFS= read -r item; do
                [[ -z "$item" ]] && continue
                local commit_date
                commit_date=$(echo "$item" | jq -r '.commit.author.date' | cut -d'T' -f1)
                local -n activity_ref=$activity_array_ref
                activity_ref["$commit_date"]=$((${activity_ref[$commit_date]:-0} + 1))
              done <<< "$items"

              # Check pagination
              local items_count
              items_count=$(echo "$response" | jq '.items | length')
              if (( items_count < ITEMS_PER_PAGE )); then
                break
              fi
              
              page=$((page + 1))
              sleep 0.1  # Rate limiting courtesy
            done
          }

          # Recursive function to handle large date ranges
          fetch_activity_range() {
            local start_date=$1
            local end_date=$2
            local activity_array_ref=$3
            local query="author:${USER} committer-date:${start_date}..${end_date}"
            
            echo "Checking range: $start_date to $end_date"
            
            local encoded_query
            encoded_query=$(printf '%s' "$query" | jq -sRr @uri)
            local summary_url="https://api.github.com/search/commits?q=${encoded_query}&per_page=1"
            
            local summary_response
            summary_response=$(api_request "$summary_url") || return 1
            
            local total_count
            total_count=$(echo "$summary_response" | jq -r '.total_count // 0')

            if (( total_count >= 1000 )); then
              # Split range in half
              local start_ts end_ts mid_ts mid_date
              start_ts=$(date -d "$start_date" +%s)
              end_ts=$(date -d "$end_date" +%s)
              mid_ts=$(( (start_ts + end_ts) / 2 ))
              mid_date=$(date -u -d "@$mid_ts" +%F)
              
              if [[ "$mid_date" == "$start_date" || "$mid_date" == "$end_date" ]]; then
                echo "::warning::Cannot split range further: $start_date..$end_date (total: $total_count)"
                process_range_pages "$start_date" "$end_date" "$activity_array_ref"
              else
                fetch_activity_range "$start_date" "$mid_date" "$activity_array_ref"
                local next_day
                next_day=$(date -u -d "$mid_date +1 day" +%F)
                if [[ $(date -d "$next_day" +%s) -le $(date -d "$end_date" +%s) ]]; then
                  fetch_activity_range "$next_day" "$end_date" "$activity_array_ref"
                fi
              fi
            else
              process_range_pages "$start_date" "$end_date" "$activity_array_ref"
            fi
          }

          # Function to generate JSON output
          generate_json_output() {
            local output_file=$1
            local start_date=$2
            local end_date=$3
            local activity_array_ref=$4
            local period_type=$5
            
            local -n activity_ref=$activity_array_ref
            
            {
              echo "{"
              echo "  \"metadata\": {"
              echo "    \"generated_at\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\","
              if [[ "$period_type" == "yearly" ]]; then
                echo "    \"target_year\": $YEAR,"
              else
                echo "    \"period_type\": \"rolling_365_days\","
              fi
              echo "    \"target_user\": \"$USER\","
              echo "    \"date_range\": {"
              echo "      \"start\": \"$start_date\","
              echo "      \"end\": \"$end_date\""
              echo "    },"
              echo "    \"workflow_run\": \"${{ github.run_id }}\""
              echo "  },"
              echo "  \"daily_metrics\": {"
              
              # Generate daily entries for the date range
              is_first=true
              current_date="$start_date"
              end_timestamp=$(date -d "$end_date" +%s)
              
              while [[ $(date -d "$current_date" +%s) -le $end_timestamp ]]; do
                count=${activity_ref[$current_date]:-0}
                
                if [[ "$is_first" == "true" ]]; then
                  is_first=false
                else
                  echo ","
                fi
                
                printf "    \"%s\": %d" "$current_date" "$count"
                current_date=$(date -I -d "$current_date +1 day")
              done
              
              echo
              echo "  }"
              echo "}"
            } > "$output_file"
          }

          # Generate yearly data
          declare -A yearly_activity
          YEAR_START="${YEAR}-01-01"
          YEAR_END="${YEAR}-12-31"

          echo "=== Starting yearly activity aggregation for $USER in $YEAR ==="
          fetch_activity_range "$YEAR_START" "$YEAR_END" "yearly_activity"
          generate_json_output "$OUT_FILE" "$YEAR_START" "$YEAR_END" "yearly_activity" "yearly"
          echo "✓ Yearly activity aggregation completed: $OUT_FILE"

          # Generate rolling 365-day data
          declare -A rolling_activity
          
          echo "=== Starting rolling 365-day activity aggregation for $USER ==="
          echo "Date range: $TWELVE_MONTHS_START to $TODAY"
          fetch_activity_range "$TWELVE_MONTHS_START" "$TODAY" "rolling_activity"
          generate_json_output "$ROLLING_OUT_FILE" "$TWELVE_MONTHS_START" "$TODAY" "rolling_activity" "rolling"
          echo "✓ Rolling 365-day activity aggregation completed: $ROLLING_OUT_FILE"

      - name: Validate generated data
        run: |
          OUTPUT_FILE="${{ steps.config.outputs.output_file }}"
          ROLLING_OUTPUT_FILE="${{ steps.config.outputs.rolling_output_file }}"

          validate_file() {
            local file=$1
            local description=$2
            
            # Check file exists
            if [[ ! -f "$file" ]]; then
              echo "::error::$description file not generated: $file"
              return 1
            fi

            # Validate JSON format
            if ! jq empty "$file" 2>/dev/null; then
              echo "::error::Invalid JSON format in $file"
              return 1
            fi

            # Generate summary
            echo "=== $description Data Summary ==="
            echo "File: $file"
            echo "Size: $(du -h "$file" | cut -f1)"
            echo "Total days: $(jq '.daily_metrics | length' "$file")"
            echo "Active days: $(jq '[.daily_metrics[] | select(. > 0)] | length' "$file")"
            echo "Total activity: $(jq '[.daily_metrics[]] | add' "$file")"
            
            echo -e "\n=== $description File Preview ==="
            head -n 20 "$file"
            echo ""
          }

          validate_file "$OUTPUT_FILE" "Yearly"
          validate_file "$ROLLING_OUTPUT_FILE" "Rolling 365-Day"

      - name: Commit data changes
        run: |
          OUTPUT_FILE="${{ steps.config.outputs.output_file }}"
          ROLLING_OUTPUT_FILE="${{ steps.config.outputs.rolling_output_file }}"
          YEAR="${{ steps.config.outputs.target_year }}"
          USER="${{ steps.config.outputs.target_user }}"

          # Configure git
          git config --local user.name "github-actions[bot]"
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Check for changes in both files
          git add "$OUTPUT_FILE" "$ROLLING_OUTPUT_FILE"
          
          if git diff --staged --quiet; then
            echo "No changes detected in activity files"
          else
            # Create conventional commit message
            COMMIT_MSG="Auto-generated activity aggregation for user ${USER}
          - Updated yearly activity metrics (${YEAR})
          - Updated rolling 365-day activity metrics
          - Data source: GitHub Search API  
          - Workflow run: ${{ github.run_id }}
          
          [skip ci]"
            
            git commit -m "feat(analytics): update activity metrics for ${USER}" -m "$COMMIT_MSG"
            git push origin HEAD
            echo "✓ Successfully committed updates to activity files"
          fi
